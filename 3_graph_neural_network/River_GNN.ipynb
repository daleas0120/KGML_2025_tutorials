{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "datapath = '/content/drive/MyDrive/kgml'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6CczT_1CqdS",
        "outputId": "c0817be6-0e71-4a1d-a384-0cb2e8befb19"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install torch-geometric\n",
        "!pip install torchinfo\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZY7SOtUDPCa",
        "outputId": "63228be0-f1ee-49e3-db75-65c45a37d79f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.7.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.12.14)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.7.14)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.14.1)\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "import torch\n",
        "import urllib.request\n",
        "\n",
        "from torch_geometric.data import Data, Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "import sys\n",
        "import types\n",
        "\n",
        "class LamaHDataset(Dataset):\n",
        "    DATA_URL = \"https://zenodo.org/record/5153305/files/1_LamaH-CE_daily_hourly.tar.gz\"\n",
        "    Q_COL = \"qobs\"\n",
        "    MET_COLS = [\n",
        "        \"prec\",  # precipitation\n",
        "        \"volsw_123\",  # topsoil moisture\n",
        "        \"2m_temp\",  # air temperature\n",
        "        \"surf_press\",  # surface pressure\n",
        "    ]\n",
        "\n",
        "    def __init__(self, root_dir, years=range(2000, 2018), root_gauge_id=399, rewire_graph=True,\n",
        "                 window_size=24, stride_length=1, lead_time=6, normalized=False):\n",
        "        if not set(years).issubset(range(2000, 2018)):\n",
        "            raise ValueError(\"Only years between 2000 and 2017 are supported\")\n",
        "\n",
        "        self.years = years\n",
        "        self.root_gauge_id = root_gauge_id\n",
        "        self.rewire_graph = rewire_graph\n",
        "        self.window_size = window_size\n",
        "        self.stride_length = stride_length\n",
        "        self.lead_time = lead_time\n",
        "        self.normalized = normalized\n",
        "\n",
        "        super().__init__(root_dir)  # calls download() and process() if necessary\n",
        "\n",
        "        adj_df = pd.read_csv(self.processed_paths[0])\n",
        "        self.gauges = list(sorted(set(adj_df[\"ID\"]).union(adj_df[\"NEXTDOWNID\"])))\n",
        "        rev_index = {gauge_id: i for i, gauge_id in enumerate(self.gauges)}\n",
        "        edge_cols = adj_df[[\"ID\", \"NEXTDOWNID\"]].applymap(lambda x: rev_index[x])\n",
        "        self.edge_index = torch.tensor(edge_cols.values.transpose(), dtype=torch.long)\n",
        "        weight_cols = adj_df[[\"dist_hdn\", \"elev_diff\", \"strm_slope\"]]\n",
        "        self.edge_attr = torch.tensor(weight_cols.values, dtype=torch.float)\n",
        "\n",
        "        stats_df = pd.read_csv(self.processed_paths[1], index_col=\"ID\")\n",
        "        self.mean = torch.tensor(stats_df[[f\"{col}_mean\" for col in [self.Q_COL] + self.MET_COLS]].values,\n",
        "                                 dtype=torch.float)\n",
        "        self.std = torch.tensor(stats_df[[f\"{col}_std\" for col in [self.Q_COL] + self.MET_COLS]].values,\n",
        "                                dtype=torch.float)\n",
        "\n",
        "        self.year_sizes = [(24 * (365 + int(year % 4 == 0)) - (window_size + lead_time)) // stride_length + 1\n",
        "                           for year in years]\n",
        "        self.year_tensors = [[] for _ in years]\n",
        "        print(\"Loading dataset into memory...\")\n",
        "        for gauge_id in tqdm(self.gauges):\n",
        "            q_df = pd.read_csv(f\"{self.raw_dir}/{self.raw_file_names[2]}/hourly/ID_{gauge_id}.csv\",\n",
        "                               sep=\";\", usecols=[\"YYYY\"] + [self.Q_COL])\n",
        "            met_df = pd.read_csv(f\"{self.raw_dir}/{self.raw_file_names[1]}/hourly/ID_{gauge_id}.csv\",\n",
        "                                 sep=\";\", usecols=[\"YYYY\"] + self.MET_COLS)\n",
        "            if normalized:\n",
        "                q_df[self.Q_COL] = (q_df[self.Q_COL] - stats_df.loc[gauge_id, f\"{self.Q_COL}_mean\"]) / stats_df.loc[\n",
        "                    gauge_id, f\"{self.Q_COL}_std\"]\n",
        "                for col in self.MET_COLS:\n",
        "                    met_df[col] = (met_df[col] - stats_df.loc[gauge_id, f\"{col}_mean\"]) / stats_df.loc[\n",
        "                        gauge_id, f\"{col}_std\"]\n",
        "            for i, year in enumerate(years):\n",
        "                q_tensor = torch.tensor(q_df[q_df[\"YYYY\"] == year][self.Q_COL].values, dtype=torch.float).unsqueeze(-1)\n",
        "                met_tensor = torch.tensor(met_df[met_df[\"YYYY\"] == year][self.MET_COLS].values, dtype=torch.float)\n",
        "                self.year_tensors[i].append(torch.cat([q_tensor, met_tensor], dim=1))\n",
        "        self.year_tensors[:] = map(torch.stack, self.year_tensors)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return [\"B_basins_intermediate_all/1_attributes\",\n",
        "                \"B_basins_intermediate_all/2_timeseries\",\n",
        "                \"D_gauges/2_timeseries\"]\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return [f\"adjacency_{self.root_gauge_id}_{self.rewire_graph}.csv\",\n",
        "                f\"statistics_{self.root_gauge_id}_{self.rewire_graph}.csv\"]\n",
        "\n",
        "    def download(self):\n",
        "        print(\"Downloading LamaH-CE from Zenodo to\", self.raw_dir)\n",
        "        total_size = int(urllib.request.urlopen(self.DATA_URL).info().get(\"Content-Length\"))\n",
        "        with tqdm(total=total_size, unit=\"B\", unit_scale=True, unit_divisor=1024, desc=\"Downloading\") as pbar:\n",
        "            filename, _ = urllib.request.urlretrieve(self.DATA_URL,\n",
        "                                                     filename=\"./archive.tar\",\n",
        "                                                     reporthook=lambda _, n, __: pbar.update(n))\n",
        "        archive = tarfile.open(filename)\n",
        "        for member in tqdm(archive.getmembers(), desc=\"Extracting\"):\n",
        "            if member.name.startswith(tuple(self.raw_file_names)):\n",
        "                archive.extract(member, self.raw_dir)\n",
        "        os.remove(filename)\n",
        "\n",
        "    def process(self):\n",
        "        adj_df = pd.read_csv(f\"{self.raw_dir}/{self.raw_file_names[0]}/Stream_dist.csv\", sep=\";\")\n",
        "        adj_df.drop(columns=\"strm_slope\", inplace=True)  # will re-calculate from dist_hdn and elev_diff\n",
        "\n",
        "        stats_df = pd.DataFrame(\n",
        "            columns=sum([[f\"{col}_mean\", f\"{col}_std\"] for col in [self.Q_COL] + self.MET_COLS], []),\n",
        "            index=pd.Index([], name=\"ID\")\n",
        "        )\n",
        "\n",
        "        connected_gauges = set(adj_df[\"ID\"]).union(adj_df[\"NEXTDOWNID\"])\n",
        "        print(f\"Discovering feasible gauges...\")\n",
        "        feasible_gauges = set(self._collect_upstream(self.root_gauge_id, adj_df, stats_df))\n",
        "        print()\n",
        "        assert feasible_gauges.issubset(connected_gauges)\n",
        "        print(f\"Discovered {len(feasible_gauges)} feasible gauges starting at ID {self.root_gauge_id} \"\n",
        "              + (\"with graph rewiring\" if self.rewire_graph else \"without graph rewiring\"))\n",
        "\n",
        "        for gauge_id in tqdm(connected_gauges - feasible_gauges, desc=\"Bad gauge removal\"):\n",
        "            adj_df = self._remove_gauge_edges(gauge_id, adj_df)\n",
        "\n",
        "        print(\"Saving final adjacency list to\", self.processed_paths[0])\n",
        "        adj_df[\"strm_slope\"] = adj_df[\"elev_diff\"] / adj_df[\"dist_hdn\"]  # re-calculate\n",
        "        adj_df.sort_values(by=\"ID\", inplace=True)\n",
        "        adj_df.to_csv(self.processed_paths[0], index=False)\n",
        "\n",
        "        print(\"Saving feature summary statistics to\", self.processed_paths[1], end=\"\\n\\n\")\n",
        "        stats_df.sort_values(by=\"ID\", inplace=True)\n",
        "        stats_df.to_csv(self.processed_paths[1], index=True)\n",
        "\n",
        "    def _collect_upstream(self, gauge_id, adj_df, stats_df):\n",
        "        print(f\"Processing gauge #{gauge_id}\", end=\"\\r\", flush=True)\n",
        "        collected_ids = set()\n",
        "        is_valid, gauge_stats = self._has_valid_data(gauge_id)\n",
        "        if is_valid:\n",
        "            collected_ids.add(gauge_id)\n",
        "            stats_df.loc[gauge_id] = gauge_stats\n",
        "        if is_valid or self.rewire_graph:\n",
        "            predecessor_ids = set(adj_df[adj_df[\"NEXTDOWNID\"] == gauge_id][\"ID\"])\n",
        "            collected_ids.update(*[self._collect_upstream(pred_id, adj_df, stats_df) for pred_id in predecessor_ids])\n",
        "        return collected_ids\n",
        "\n",
        "    def _has_valid_data(self, gauge_id):\n",
        "        q_df = pd.read_csv(f\"{self.raw_dir}/{self.raw_file_names[2]}/hourly/ID_{gauge_id}.csv\",\n",
        "                           sep=\";\", usecols=[\"YYYY\", self.Q_COL])\n",
        "        met_df = pd.read_csv(f\"{self.raw_dir}/{self.raw_file_names[1]}/hourly/ID_{gauge_id}.csv\",\n",
        "                             sep=\";\", usecols=[\"YYYY\"] + self.MET_COLS)\n",
        "        if (q_df[self.Q_COL] > 0).all() and (q_df[self.Q_COL] <= 1e30).all():\n",
        "            q_df = q_df[(q_df[\"YYYY\"] >= 2000) & (q_df[\"YYYY\"] <= 2017)]\n",
        "            met_df = met_df[(met_df[\"YYYY\"] >= 2000) & (met_df[\"YYYY\"] <= 2017)]\n",
        "            if len(q_df) == (18 * 365 + 5) * 24 and len(met_df) == (18 * 365 + 5) * 24:  # number of hours in 2000-2017\n",
        "                q_df_train = q_df[q_df[\"YYYY\"] <= 2015]\n",
        "                met_df_train = met_df[met_df[\"YYYY\"] <= 2015]\n",
        "                return True, [q_df_train[self.Q_COL].mean(), q_df_train[self.Q_COL].std()] \\\n",
        "                             + sum([[met_df_train[col].mean(), met_df_train[col].std()] for col in self.MET_COLS], [])\n",
        "        return False, None\n",
        "\n",
        "    def _remove_gauge_edges(self, gauge_id, adj_df):\n",
        "        incoming_edges = adj_df.loc[adj_df[\"NEXTDOWNID\"] == gauge_id]\n",
        "        outgoing_edges = adj_df.loc[adj_df[\"ID\"] == gauge_id]\n",
        "\n",
        "        adj_df.drop(labels=incoming_edges.index, inplace=True)\n",
        "        adj_df.drop(labels=outgoing_edges.index, inplace=True)\n",
        "\n",
        "        if self.rewire_graph:  # need to rewire nodes that are adjacent to a deleted node\n",
        "            bypass = incoming_edges.merge(outgoing_edges, how=\"cross\", suffixes=[\"\", \"_\"])\n",
        "            bypass[\"NEXTDOWNID\"] = bypass[\"NEXTDOWNID_\"]\n",
        "            bypass[\"dist_hdn\"] += bypass[\"dist_hdn_\"]\n",
        "            bypass[\"elev_diff\"] += bypass[\"elev_diff_\"]\n",
        "            adj_df = pd.concat([adj_df, bypass[[\"ID\", \"NEXTDOWNID\", \"dist_hdn\", \"elev_diff\"]]],\n",
        "                               ignore_index=True, copy=False)\n",
        "\n",
        "        return adj_df.reset_index(drop=True)\n",
        "\n",
        "    def len(self):\n",
        "        return sum(self.year_sizes)\n",
        "\n",
        "    def get(self, idx):\n",
        "        year_tensor, offset = self._decode_index(idx)\n",
        "        x = year_tensor[:, offset:(offset + self.window_size)]\n",
        "        y = year_tensor[:, offset + self.window_size + (self.lead_time - 1), 0]\n",
        "        return Data(x=x, y=y.unsqueeze(-1), edge_index=self.edge_index, edge_attr=self.edge_attr)\n",
        "\n",
        "    def _decode_index(self, idx):\n",
        "        for i, size in enumerate(self.year_sizes):\n",
        "            idx -= size\n",
        "            if idx < 0:\n",
        "                return self.year_tensors[i], self.stride_length * (idx + size)\n",
        "        raise AssertionError(\"Corrupt internal state. This should never happen!\")\n",
        "\n",
        "    def normalize(self, x):\n",
        "        return (x - self.mean[:, None, :]) / self.std[:, None, :]\n",
        "\n",
        "    def denormalize(self, x):\n",
        "        return self.std[:, None, :] * x + self.mean[:, None, :]\n",
        "\n",
        "    def longest_path(self):\n",
        "        def longest_upstream_path(gauge_idx):\n",
        "            predecessor_ids = self.edge_index[0, self.edge_index[1] == gauge_idx].tolist()\n",
        "            if not predecessor_ids:\n",
        "                return 0\n",
        "            else:\n",
        "                return 1 + max(longest_upstream_path(pred_id) for pred_id in predecessor_ids)\n",
        "\n",
        "        return max(longest_upstream_path(start_idx) for start_idx in self.edge_index[1].unique())\n"
      ],
      "metadata": {
        "id": "E099nHJgIl2w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CqqxCeN1DRjP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "from torch.nn import Module, ModuleList, LSTM\n",
        "from torch.nn.functional import mse_loss, relu\n",
        "from torch_geometric.nn import GATConv, GCNConv, GCN2Conv, Linear\n",
        "from torch_geometric.utils import add_self_loops\n",
        "\n",
        "\n",
        "class BaseModel(Module, ABC):\n",
        "    def __init__(self, in_channels, hidden_channels, num_hidden, param_sharing, layerfun, edge_orientation, edge_weights):\n",
        "        super().__init__()\n",
        "        self.encoder = Linear(in_channels, hidden_channels, weight_initializer=\"kaiming_uniform\")\n",
        "        self.decoder = Linear(hidden_channels, 1, weight_initializer=\"kaiming_uniform\")\n",
        "        if param_sharing:\n",
        "            self.layers = ModuleList(num_hidden * [layerfun()])\n",
        "        else:\n",
        "            self.layers = ModuleList([layerfun() for _ in range(num_hidden)])\n",
        "        self.edge_weights = edge_weights\n",
        "        self.edge_orientation = edge_orientation\n",
        "        if self.edge_weights is not None:\n",
        "            self.loop_fill_value = 1.0 if (self.edge_weights == 0).all() else \"mean\"\n",
        "\n",
        "    def forward(self, x, edge_index, evo_tracking=False):\n",
        "        x = x.flatten(1)\n",
        "        if self.edge_weights is not None:\n",
        "            num_graphs = edge_index.size(1) // len(self.edge_weights)\n",
        "            edge_weights = torch.cat(num_graphs * [self.edge_weights], dim=0).to(x.device)\n",
        "            edge_weights = edge_weights.abs()  # relevant when edge weights are learned\n",
        "        else:\n",
        "            edge_weights = torch.zeros(edge_index.size(1)).to(x.device)\n",
        "\n",
        "        if self.edge_orientation is not None:\n",
        "            if self.edge_orientation == \"upstream\":\n",
        "                edge_index = edge_index[[1, 0]].to(x.device)\n",
        "            elif self.edge_orientation == \"bidirectional\":\n",
        "                edge_index = torch.cat([edge_index, edge_index[[1, 0]]], dim=1).to(x.device)\n",
        "                edge_weights = torch.cat(2 * [edge_weights], dim=0).to(x.device)\n",
        "            elif self.edge_orientation != \"downstream\":\n",
        "                raise ValueError(\"unknown edge direction\", self.edge_orientation)\n",
        "        if self.edge_weights is not None:\n",
        "            edge_index, edge_weights = add_self_loops(edge_index, edge_weights, fill_value=self.loop_fill_value)\n",
        "\n",
        "        x_0 = self.encoder(x)\n",
        "        evolution = [x_0.detach()] if evo_tracking else None\n",
        "\n",
        "        x = x_0\n",
        "        for layer in self.layers:\n",
        "            x = self.apply_layer(layer, x, x_0, edge_index, edge_weights)\n",
        "            if evo_tracking:\n",
        "                evolution.append(x.detach())\n",
        "        x = self.decoder(x)\n",
        "\n",
        "        if evo_tracking:\n",
        "            return x, evolution\n",
        "        return x\n",
        "\n",
        "    @abstractmethod\n",
        "    def apply_layer(self, layer, x, x_0, edge_index, edge_weights):\n",
        "        pass\n",
        "\n",
        "\n",
        "class MLP(BaseModel):\n",
        "    def __init__(self, in_channels, hidden_channels, num_hidden, param_sharing):\n",
        "        layer_gen = lambda: Linear(hidden_channels, hidden_channels, weight_initializer=\"kaiming_uniform\")\n",
        "        super().__init__(in_channels, hidden_channels, num_hidden, param_sharing, layer_gen, None, None)\n",
        "\n",
        "    def apply_layer(self, layer, x, x_0, edge_index, edge_weights):\n",
        "        return relu(layer(x))\n",
        "\n",
        "\n",
        "class GCN(BaseModel):\n",
        "    def __init__(self, in_channels, hidden_channels, num_hidden, param_sharing, edge_orientation, edge_weights):\n",
        "        layer_gen = lambda: GCNConv(hidden_channels, hidden_channels, add_self_loops=False)\n",
        "        super().__init__(in_channels, hidden_channels, num_hidden, param_sharing, layer_gen, edge_orientation, edge_weights)\n",
        "\n",
        "    def apply_layer(self, layer, x, x_0, edge_index, edge_weights):\n",
        "        return relu(layer(x, edge_index, edge_weights))\n",
        "\n",
        "\n",
        "class ResGCN(GCN):\n",
        "    def __init__(self, in_channels, hidden_channels, num_hidden, param_sharing, edge_orientation, edge_weights):\n",
        "        super().__init__(in_channels, hidden_channels, num_hidden, param_sharing, edge_orientation, edge_weights)\n",
        "\n",
        "    def apply_layer(self, layer, x, x_0, edge_index, edge_weights):\n",
        "        return x + super().apply_layer(layer, x, x_0, edge_index, edge_weights)\n",
        "\n",
        "\n",
        "class GCNII(BaseModel):\n",
        "    def __init__(self, in_channels, hidden_channels, num_hidden, param_sharing, edge_orientation, edge_weights):\n",
        "        layer_gen = lambda: GCN2Conv(hidden_channels, alpha=0.5, add_self_loops=False)\n",
        "        super().__init__(in_channels, hidden_channels, num_hidden, param_sharing, layer_gen, edge_orientation, edge_weights)\n",
        "\n",
        "    def apply_layer(self, layer, x, x_0, edge_index, edge_weights):\n",
        "        return relu(layer(x, x_0, edge_index, edge_weights))\n",
        "\n",
        "\n",
        "class ResGAT(BaseModel):\n",
        "    def __init__(self, in_channels, hidden_channels, num_hidden, param_sharing, edge_orientation, edge_weights):\n",
        "        layer_gen = lambda: GATConv(hidden_channels, hidden_channels, add_self_loops=False)\n",
        "        super().__init__(in_channels, hidden_channels, num_hidden, param_sharing, layer_gen, edge_orientation, edge_weights)\n",
        "\n",
        "    def apply_layer(self, layer, x, x_0, edge_index, edge_weights):\n",
        "        if edge_weights.dim() == 1:\n",
        "            edge_index = edge_index[:, edge_weights != 0]\n",
        "        return x + relu(layer(x, edge_index, edge_weights))"
      ],
      "metadata": {
        "id": "0XwzjMftC5RS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HrAxXfYmClnt"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# from dataset import LamaHDataset\n",
        "# from models import MLP, GCN, ResGCN, GCNII, ResGAT\n",
        "from torch.nn.functional import mse_loss\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.data import Batch\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.utils import get_laplacian, to_undirected, to_torch_coo_tensor\n",
        "\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def ensure_reproducibility(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def get_edge_weights(adjacency_type, edge_attr):\n",
        "    if adjacency_type == \"isolated\":\n",
        "        return torch.zeros(edge_attr.size(0))\n",
        "    elif adjacency_type == \"binary\":\n",
        "        return torch.ones(edge_attr.size(0))\n",
        "    elif adjacency_type == \"stream_length\":\n",
        "        return edge_attr[:, 0]\n",
        "    elif adjacency_type == \"elevation_difference\":\n",
        "        return edge_attr[:, 1]\n",
        "    elif adjacency_type == \"average_slope\":\n",
        "        return edge_attr[:, 2]\n",
        "    elif adjacency_type == \"learned\":\n",
        "        return nn.Parameter(torch.nn.init.uniform_(torch.empty(edge_attr.size(0)), 0.9, 1.1))\n",
        "    elif adjacency_type == \"all\":\n",
        "        return edge_attr[:, :]\n",
        "    else:\n",
        "        raise ValueError(\"invalid adjacency type\", adjacency_type)\n",
        "\n",
        "\n",
        "def construct_model(hparams, dataset):\n",
        "    edge_weights = get_edge_weights(hparams[\"model\"][\"adjacency_type\"], dataset.edge_attr)\n",
        "    model_arch = hparams[\"model\"][\"architecture\"]\n",
        "    if model_arch == \"MLP\":\n",
        "        return MLP(in_channels=hparams[\"data\"][\"window_size\"] * (1 + len(dataset.MET_COLS)),\n",
        "                   hidden_channels=hparams[\"model\"][\"hidden_channels\"],\n",
        "                   num_hidden=hparams[\"model\"][\"num_layers\"],\n",
        "                   param_sharing=hparams[\"model\"][\"param_sharing\"])\n",
        "    elif model_arch == \"GCN\":\n",
        "        return GCN(in_channels=hparams[\"data\"][\"window_size\"] * (1 + len(dataset.MET_COLS)),\n",
        "                   hidden_channels=hparams[\"model\"][\"hidden_channels\"],\n",
        "                   num_hidden=hparams[\"model\"][\"num_layers\"],\n",
        "                   param_sharing=hparams[\"model\"][\"param_sharing\"],\n",
        "                   edge_orientation=hparams[\"model\"][\"edge_orientation\"],\n",
        "                   edge_weights=edge_weights\n",
        "                   )\n",
        "    elif model_arch == \"ResGCN\":\n",
        "        return ResGCN(in_channels=hparams[\"data\"][\"window_size\"] * (1 + len(dataset.MET_COLS)),\n",
        "                      hidden_channels=hparams[\"model\"][\"hidden_channels\"],\n",
        "                      num_hidden=hparams[\"model\"][\"num_layers\"],\n",
        "                      param_sharing=hparams[\"model\"][\"param_sharing\"],\n",
        "                      edge_orientation=hparams[\"model\"][\"edge_orientation\"],\n",
        "                      edge_weights=edge_weights)\n",
        "    elif model_arch == \"GCNII\":\n",
        "        return GCNII(in_channels=hparams[\"data\"][\"window_size\"] * (1 + len(dataset.MET_COLS)),\n",
        "                     hidden_channels=hparams[\"model\"][\"hidden_channels\"],\n",
        "                     num_hidden=hparams[\"model\"][\"num_layers\"],\n",
        "                     param_sharing=hparams[\"model\"][\"param_sharing\"],\n",
        "                     edge_orientation=hparams[\"model\"][\"edge_orientation\"],\n",
        "                     edge_weights=edge_weights)\n",
        "    elif model_arch == \"ResGAT\":\n",
        "        return ResGAT(in_channels=hparams[\"data\"][\"window_size\"] * (1 + len(dataset.MET_COLS)),\n",
        "                      hidden_channels=hparams[\"model\"][\"hidden_channels\"],\n",
        "                      num_hidden=hparams[\"model\"][\"num_layers\"],\n",
        "                      param_sharing=hparams[\"model\"][\"param_sharing\"],\n",
        "                      edge_orientation=hparams[\"model\"][\"edge_orientation\"],\n",
        "                      edge_weights=edge_weights)\n",
        "    raise ValueError(\"unknown model architecture\", model_arch)\n",
        "\n",
        "\n",
        "def load_dataset(path, hparams, split):\n",
        "    if split == \"train\":\n",
        "        years = hparams[\"training\"][\"train_years\"]\n",
        "    elif split == \"test\":\n",
        "        years = [2016, 2017]\n",
        "    else:\n",
        "        raise ValueError(\"unknown split\", split)\n",
        "    return LamaHDataset(path,\n",
        "                        years=years,\n",
        "                        root_gauge_id=hparams[\"data\"][\"root_gauge_id\"],\n",
        "                        rewire_graph=hparams[\"data\"][\"rewire_graph\"],\n",
        "                        window_size=hparams[\"data\"][\"window_size\"],\n",
        "                        stride_length=hparams[\"data\"][\"stride_length\"],\n",
        "                        lead_time=hparams[\"data\"][\"lead_time\"],\n",
        "                        normalized=hparams[\"data\"][\"normalized\"])\n",
        "\n",
        "\n",
        "def load_model_and_dataset(chkpt, dataset_path):\n",
        "    model_params = chkpt[\"history\"][\"best_model_params\"]\n",
        "    dataset = load_dataset(dataset_path, chkpt[\"hparams\"], split=\"test\")\n",
        "    model = construct_model(chkpt[\"hparams\"], dataset)\n",
        "    model.load_state_dict(model_params, strict=False)\n",
        "    return model, dataset\n",
        "\n",
        "\n",
        "def train_step(model, train_loader, criterion, optimizer, device, reset_running_loss_after=10):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    running_loss = 0.0\n",
        "    running_counter = 1\n",
        "    with tqdm(train_loader, desc=\"Training\") as pbar:\n",
        "        for batch in pbar:\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(batch.x, batch.edge_index)\n",
        "            loss = criterion(pred, batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * batch.num_graphs / len(train_loader.dataset)\n",
        "            running_loss += loss.item() / reset_running_loss_after\n",
        "            running_counter += 1\n",
        "            if running_counter >= reset_running_loss_after:\n",
        "                pbar.set_postfix({\"loss\": running_loss})\n",
        "                running_counter = 1\n",
        "                running_loss = 0.0\n",
        "    return train_loss\n",
        "\n",
        "\n",
        "def val_step(model, val_loader, criterion, device, reset_running_loss_after=10):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    running_loss = 0.0\n",
        "    running_counter = 1\n",
        "    with torch.no_grad():\n",
        "        with tqdm(val_loader, desc=\"Validating\") as pbar:\n",
        "            for batch in pbar:\n",
        "                batch = batch.to(device)\n",
        "                pred = model(batch.x, batch.edge_index)\n",
        "                loss = criterion(pred, batch)\n",
        "                val_loss += loss.item() * batch.num_graphs / len(val_loader.dataset)\n",
        "                running_loss += loss.item() / reset_running_loss_after\n",
        "                running_counter += 1\n",
        "                if running_counter >= reset_running_loss_after:\n",
        "                    pbar.set_postfix({\"loss\": running_loss})\n",
        "                    running_counter = 1\n",
        "                    running_loss = 0.0\n",
        "    return val_loss\n",
        "\n",
        "\n",
        "def interestingness_score(batch, dataset, device):\n",
        "    mean = dataset.mean[:, None, 0].repeat(batch.num_graphs, 1).to(device)\n",
        "    std = dataset.std[:, None, 0].repeat(batch.num_graphs, 1).to(device)\n",
        "    unnormalized_discharge = mean + std * batch.x[:, :, 0]\n",
        "    assert unnormalized_discharge.min() >= 0.0\n",
        "    comparable_discharge = unnormalized_discharge / mean\n",
        "\n",
        "    mean_central_diff = torch.gradient(comparable_discharge, dim=-1)[0].mean()\n",
        "    trapezoid_integral = torch.trapezoid(comparable_discharge, dim=-1)\n",
        "\n",
        "    score = 1e3 * (mean_central_diff ** 2) * trapezoid_integral\n",
        "    assert not trapezoid_integral.isinf().any()\n",
        "    assert not trapezoid_integral.isnan().any()\n",
        "    return score.unsqueeze(-1)\n",
        "\n",
        "\n",
        "def interestingness_score_normalization_const(loader, device):\n",
        "    total_score = 0.0\n",
        "    for batch in tqdm(loader, desc=\"Summing all scores\"):\n",
        "        total_score += interestingness_score(batch, loader.dataset, device).item()\n",
        "    return total_score\n",
        "\n",
        "\n",
        "def train(model, dataset, hparams):\n",
        "\n",
        "    print(summary(model, depth=2))\n",
        "\n",
        "    holdout_size = hparams[\"training\"][\"holdout_size\"]\n",
        "    dataset_length = len(dataset)\n",
        "    val_size = int(holdout_size * dataset_length)\n",
        "    train_size = dataset_length - val_size\n",
        "\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "    train_loader = DataLoader(train_dataset, batch_size=hparams[\"training\"][\"batch_size\"], shuffle=True, num_workers=2,\n",
        "                              pin_memory=True, drop_last=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=hparams[\"training\"][\"batch_size\"], shuffle=False, num_workers=2,\n",
        "                            pin_memory=True, drop_last=True)\n",
        "\n",
        "    # print(summary(model, depth=2))\n",
        "\n",
        "    # holdout_size = hparams[\"training\"][\"holdout_size\"]\n",
        "    # train_dataset, val_dataset = random_split(dataset, [1 - holdout_size, holdout_size])\n",
        "    train_loader = DataLoader(train_dataset, batch_size=hparams[\"training\"][\"batch_size\"], shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=hparams[\"training\"][\"batch_size\"], shuffle=False)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    criterion = lambda pred, batch: (interestingness_score(batch, dataset, device) * mse_loss(pred, batch.y, reduction=\"none\")).mean()  # mse_loss(pred, batch.y)\n",
        "    optimizer = torch.optim.Adam(model.parameters(),\n",
        "                                 lr=hparams[\"training\"][\"learning_rate\"],\n",
        "                                 weight_decay=hparams[\"training\"][\"weight_decay\"])\n",
        "    model = model.to(device)\n",
        "    print(\"Training on\", device)\n",
        "\n",
        "    history = {\"train_loss\": [], \"val_loss\": [], \"best_model_params\": None}\n",
        "\n",
        "    min_val_loss = float(\"inf\")\n",
        "    for epoch in range(hparams[\"training\"][\"num_epochs\"]):\n",
        "        train_loss = train_step(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss = val_step(model, val_loader, criterion, device)\n",
        "\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "\n",
        "        print(\"[Epoch {0}/{1}] Train: {2:.4f} | Val {3:.4f}\".format(\n",
        "            epoch + 1, hparams[\"training\"][\"num_epochs\"], train_loss, val_loss\n",
        "        ))\n",
        "\n",
        "        if val_loss < min_val_loss:\n",
        "            min_val_loss = val_loss\n",
        "            history[\"best_model_params\"] = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "def save_checkpoint(history, hparams, filename, directory=\"./runs\"):\n",
        "    directory = directory.rstrip(\"/\")\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    out_path = f\"{directory}/{filename}\"\n",
        "    torch.save({\n",
        "        \"history\": history,\n",
        "        \"hparams\": hparams\n",
        "    }, out_path)\n",
        "    print(\"Saved checkpoint\", out_path)\n",
        "\n",
        "\n",
        "def load_checkpoint(chkpt_path):\n",
        "    return torch.load(chkpt_path, map_location=torch.device(\"cpu\"))\n",
        "\n",
        "\n",
        "def evaluate_nse(model, dataset):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    mean = dataset.mean[:, [0]].to(device)\n",
        "    std_squared = dataset.std[:, [0]].square().to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        weighted_model_error = torch.zeros(dataset[0].num_nodes, 1).to(device)\n",
        "        weighted_mean_error = torch.zeros(dataset[0].num_nodes, 1).to(device)\n",
        "        for data in tqdm(dataset, desc=\"Testing\"):\n",
        "            data = data.to(device)\n",
        "            pred = model(data.x, data.edge_index)\n",
        "            model_mse = mse_loss(pred, data.y, reduction=\"none\")\n",
        "            mean_mse = mse_loss(mean, data.y, reduction=\"none\")\n",
        "            if dataset.normalized:\n",
        "                model_mse *= std_squared\n",
        "                mean_mse *= std_squared\n",
        "            score = interestingness_score(Batch.from_data_list([data]), dataset, device)\n",
        "            weighted_model_error += score * model_mse\n",
        "            weighted_mean_error += score * mean_mse\n",
        "\n",
        "    weighted_nse = 1 - weighted_model_error / weighted_mean_error\n",
        "    return weighted_nse.cpu()\n",
        "\n",
        "\n",
        "def calculate_predictions_and_deviations_on_gauge(model, dataset, gauge_index):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    deviations = []\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(dataset, desc=\"Testing\"):\n",
        "            data = data.to(device)\n",
        "            pred = model(data.x, data.edge_index)[gauge_index]\n",
        "            target = data.y[gauge_index]\n",
        "            predictions.append(pred.item())\n",
        "            deviations.append(abs(pred - target).item())\n",
        "    return predictions, deviations\n",
        "\n",
        "\n",
        "def dirichlet_energy(x, edge_index, edge_weight, normalization=None):\n",
        "    edge_index, edge_weight = to_undirected(edge_index, edge_weight)\n",
        "    edge_index, edge_weight = get_laplacian(edge_index, edge_weight, normalization=normalization)\n",
        "    lap = to_torch_coo_tensor(edge_index=edge_index, edge_attr=edge_weight)\n",
        "    return 0.5 * torch.trace(torch.mm(x.T, torch.sparse.mm(lap, x)))\n",
        "\n",
        "\n",
        "def evaluate_dirichlet_energy(model, dataset):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    dirichlet_stats = []\n",
        "    with torch.no_grad():\n",
        "        edge_weights = model.edge_weights.detach().nan_to_num().to(device)\n",
        "        for data in tqdm(dataset, desc=\"Testing\"):\n",
        "            data = data.to(device)\n",
        "            _, evo = model(data.x, data.edge_index, evo_tracking=True)\n",
        "            dir_energies = torch.tensor([dirichlet_energy(h, data.edge_index, edge_weights) for h in evo])\n",
        "            dirichlet_stats.append(dir_energies)\n",
        "    dirichlet_stats = torch.stack(dirichlet_stats)\n",
        "    return dirichlet_stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hparams = {\n",
        "    \"data\": {\n",
        "        \"root_gauge_id\": 399,\n",
        "        \"rewire_graph\": True,\n",
        "        \"window_size\": 24,\n",
        "        \"stride_length\": 1,\n",
        "        \"lead_time\": 6,\n",
        "        \"normalized\": True,\n",
        "    },\n",
        "    \"model\": {\n",
        "        \"architecture\": None,  # set below\n",
        "        \"num_layers\": None,  # set below\n",
        "        \"hidden_channels\": 128,\n",
        "        \"param_sharing\": False,\n",
        "        \"edge_orientation\": None,  # set below\n",
        "        \"adjacency_type\": None,  # set below\n",
        "    },\n",
        "    \"training\": {\n",
        "        \"num_epochs\": 100,\n",
        "        \"batch_size\": 64,\n",
        "        \"learning_rate\": 1e-4,\n",
        "        \"weight_decay\": 1e-5,\n",
        "        \"random_seed\": 42,\n",
        "        \"train_years\": None,  # set below\n",
        "        \"holdout_size\": 1/5,\n",
        "    }\n",
        "}\n",
        "\n",
        "# DATASET_PATH = \"/path/to/LamaH-CE\"\n",
        "# CHECKPOINT_PATH = \"/path/to/checkpoint\"\n",
        "\n",
        "for fold_id, (train_years, test_years) in enumerate([(list(range(2000, 2016, 2)), [2016, 2017]),\n",
        "                                                     (list(range(2001, 2016, 2)), [2016, 2017]),\n",
        "                                                     (list(range(2008, 2016, 1)), [2016, 2017])]):\n",
        "    for architecture in [\"ResGCN\", \"GCNII\", \"ResGAT\"]:\n",
        "        for edge_orientation in [\"downstream\", \"upstream\", \"bidirectional\"]:\n",
        "            for adjacency_type in [\"isolated\", \"binary\", \"stream_length\", \"elevation_difference\", \"average_slope\", \"all\" if architecture == \"ResGAT\" else \"learned\"]:\n",
        "                hparams[\"training\"][\"train_years\"] = train_years\n",
        "                # dataset = functions.load_dataset(DATASET_PATH, hparams, split=\"train\")\n",
        "                # dataset = torch.load('/content/drive/MyDrive/kgml/demo_data.pt', weights_only=False)\n",
        "\n",
        "\n",
        "                dataset_module = types.ModuleType('dataset')\n",
        "                dataset_module.LamaHDataset = LamaHDataset\n",
        "                sys.modules['dataset'] = dataset_module\n",
        "                dataset = torch.load('/content/drive/MyDrive/kgml/demo_data.pt', weights_only=False)\n",
        "\n",
        "\n",
        "                hparams[\"model\"][\"architecture\"] = architecture\n",
        "                hparams[\"model\"][\"edge_orientation\"] = edge_orientation\n",
        "                hparams[\"model\"][\"adjacency_type\"] = adjacency_type\n",
        "                hparams[\"model\"][\"num_layers\"] = 19\n",
        "\n",
        "                ensure_reproducibility(hparams[\"training\"][\"random_seed\"])\n",
        "\n",
        "                print(hparams[\"model\"][\"num_layers\"], \"layers used\")\n",
        "                model = construct_model(hparams, dataset)\n",
        "                history = train(model, dataset, hparams)\n",
        "\n",
        "                chkpt_name = f\"{architecture}_{edge_orientation}_{adjacency_type}_{fold_id}.run\"\n",
        "                # save_checkpoint(history, hparams, chkpt_name, directory=CHECKPOINT_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "id": "BZYG11TgDN36",
        "outputId": "ec4db5a2-99d7-4d13-d929-df8b9ada936f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19 layers used\n",
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "ResGCN                                   --\n",
            "├─Linear: 1-1                            15,488\n",
            "├─Linear: 1-2                            129\n",
            "├─ModuleList: 1-3                        --\n",
            "│    └─GCNConv: 2-1                      16,512\n",
            "│    └─GCNConv: 2-2                      16,512\n",
            "│    └─GCNConv: 2-3                      16,512\n",
            "│    └─GCNConv: 2-4                      16,512\n",
            "│    └─GCNConv: 2-5                      16,512\n",
            "│    └─GCNConv: 2-6                      16,512\n",
            "│    └─GCNConv: 2-7                      16,512\n",
            "│    └─GCNConv: 2-8                      16,512\n",
            "│    └─GCNConv: 2-9                      16,512\n",
            "│    └─GCNConv: 2-10                     16,512\n",
            "│    └─GCNConv: 2-11                     16,512\n",
            "│    └─GCNConv: 2-12                     16,512\n",
            "│    └─GCNConv: 2-13                     16,512\n",
            "│    └─GCNConv: 2-14                     16,512\n",
            "│    └─GCNConv: 2-15                     16,512\n",
            "│    └─GCNConv: 2-16                     16,512\n",
            "│    └─GCNConv: 2-17                     16,512\n",
            "│    └─GCNConv: 2-18                     16,512\n",
            "│    └─GCNConv: 2-19                     16,512\n",
            "=================================================================\n",
            "Total params: 329,345\n",
            "Trainable params: 329,345\n",
            "Non-trainable params: 0\n",
            "=================================================================\n",
            "Training on cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  98%|█████████▊| 108/110 [00:08<00:00, 12.80it/s, loss=0.563]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1395131452.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_layers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"layers used\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mchkpt_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{architecture}_{edge_orientation}_{adjacency_type}_{fold_id}.run\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2864101476.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, hparams)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mmin_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2864101476.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, train_loader, criterion, optimizer, device, reset_running_loss_after)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1475241046.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, evo_tracking)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevo_tracking\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mevolution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1475241046.py\u001b[0m in \u001b[0;36mapply_layer\u001b[0;34m(self, layer, x, x_0, edge_index, edge_weights)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1475241046.py\u001b[0m in \u001b[0;36mapply_layer\u001b[0;34m(self, layer, x, x_0, edge_index, edge_weights)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_edge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                     edge_index, edge_weight = gcn_norm(  # yapf: disable\n\u001b[0m\u001b[1;32m    242\u001b[0m                         \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                         self.improved, self.add_self_loops, self.flow, x.dtype)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mdeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mdeg_inv_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mdeg_inv_sqrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeg_inv_sqrt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0medge_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeg_inv_sqrt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0medge_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdeg_inv_sqrt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RAJniLwbCxlE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}